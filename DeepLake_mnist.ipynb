{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "qxs6_sDMsmTQ",
        "ngG7vpOqsJeN",
        "k3KKKsMsikJ-",
        "k-iYGueNWgPs",
        "gPz5fEY2CyUf"
      ],
      "authorship_tag": "ABX9TyOV5kCq8Kd1h5V9fEXIA1yf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yuchenjohnlin/Mnist-on-EvaDB-and-DeepLake/blob/main/DeepLake_mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tctZN5RtbFlP"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "!pip3 install deeplake\n",
        "clear_output()\n",
        "\n",
        "#!pip install urllib3==1.26.7\n",
        "\n",
        "import deeplake"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os, time\n",
        "import torch\n",
        "from torchvision import transforms, models"
      ],
      "metadata": {
        "id": "rCRGpm2Rb10Y"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Fail data loading(Skip This part)"
      ],
      "metadata": {
        "id": "iLM6Rbh_Gts-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download the mnist dataset manually - Skip\n",
        "1. Create a dataset folder in directory\n",
        "2. download the dataset to folder\n",
        "3. unzip files\n",
        "\n",
        "Problem :\n",
        "\n",
        "the decompressed file are not images and I don't know how to use it"
      ],
      "metadata": {
        "id": "qxs6_sDMsmTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!wget \"https://www.kaggle.com/datasets/scolianni/mnistasjpg/data/trainingSet.tar.gz\""
      ],
      "metadata": {
        "id": "O7fVMHJJoulO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_folder = '/content/mnist_dataset'\n",
        "# make sure we are in the content folder\n",
        "# cwd = os.getcwd()\n",
        "# if cwd!='/content' :\n",
        "#   os.chdir('/content')\n",
        "# cwd = os.getcwd()\n",
        "# print(\"Current working directory:\", cwd)\n",
        "\n",
        "if not os.path.exists(dataset_folder):\n",
        "    os.mkdir(dataset_folder)\n",
        "    print(f\"Directory '{dataset_folder}' created successfully.\")\n",
        "else:\n",
        "    print(f\"Directory '{dataset_folder}' already exists.\")\n",
        "os.chdir(dataset_folder)\n",
        "%rm *\n",
        "cwd = os.getcwd()\n",
        "print(\"Current working directory:\", cwd)\n",
        "\n",
        "files_and_folders = os.listdir()\n",
        "print(files_and_folders)\n",
        "# Filter out only the directories from the list\n",
        "# folders = [folder for folder in files_and_folders if os.path.isdir(folder)]\n",
        "# files = [file for file in files_and_folders if os.path.isdir(file)]\n",
        "# Print the list of directories\n",
        "# print(\"Folders in the current directory:\")\n",
        "# print(folders)\n",
        "# print(\"Files in the current directory:\")\n",
        "# print(files)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQUGYbqRO-Bj",
        "outputId": "592645d5-0e79-4375-b1f0-1ba546baa55d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory '/content/mnist_dataset' already exists.\n",
            "Current working directory: /content/mnist_dataset\n",
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_url = \"http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\"\n",
        "label_url = \"http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\"\n",
        "\n",
        "data_file = os.path.basename(data_url)\n",
        "label_file = os.path.basename(label_url)\n",
        "if not os.path.exists(os.path.join(dataset_folder, data_file)):\n",
        "    # If the file does not exist, download it using wget\n",
        "    !wget -P {dataset_folder} {data_url}\n",
        "    print(\"File downloaded successfully.\")\n",
        "else:\n",
        "    print(\"File already exists. Skipping the download.\")\n",
        "\n",
        "if not os.path.exists(os.path.join(dataset_folder, label_file)):\n",
        "    # If the file does not exist, download it using wget\n",
        "    !wget -P {dataset_folder} {label_url}\n",
        "    print(\"File downloaded successfully.\")\n",
        "else:\n",
        "    print(\"File already exists. Skipping the download.\")\n",
        "\n",
        "print(\"Downloaded files in the directory:\")\n",
        "dir_files = os.listdir()\n",
        "print(dir_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RcJ3ioLpSxHk",
        "outputId": "5df700c5-6ac5-470c-9d93-7ea679111579"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-17 07:26:32--  http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Resolving yann.lecun.com (yann.lecun.com)... 104.21.29.36, 172.67.171.76, 2606:4700:3034::6815:1d24, ...\n",
            "Connecting to yann.lecun.com (yann.lecun.com)|104.21.29.36|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1648877 (1.6M) [application/x-gzip]\n",
            "Saving to: ‘/content/mnist_dataset/t10k-images-idx3-ubyte.gz’\n",
            "\n",
            "\r          t10k-imag   0%[                    ]       0  --.-KB/s               \rt10k-images-idx3-ub 100%[===================>]   1.57M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2023-10-17 07:26:33 (35.3 MB/s) - ‘/content/mnist_dataset/t10k-images-idx3-ubyte.gz’ saved [1648877/1648877]\n",
            "\n",
            "File downloaded successfully.\n",
            "--2023-10-17 07:26:33--  http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Resolving yann.lecun.com (yann.lecun.com)... 104.21.29.36, 172.67.171.76, 2606:4700:3036::ac43:ab4c, ...\n",
            "Connecting to yann.lecun.com (yann.lecun.com)|104.21.29.36|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4542 (4.4K) [application/x-gzip]\n",
            "Saving to: ‘/content/mnist_dataset/t10k-labels-idx1-ubyte.gz’\n",
            "\n",
            "t10k-labels-idx1-ub 100%[===================>]   4.44K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-10-17 07:26:33 (920 MB/s) - ‘/content/mnist_dataset/t10k-labels-idx1-ubyte.gz’ saved [4542/4542]\n",
            "\n",
            "File downloaded successfully.\n",
            "Downloaded files in the directory:\n",
            "['t10k-images-idx3-ubyte.gz', 't10k-labels-idx1-ubyte.gz']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. unzip the files"
      ],
      "metadata": {
        "id": "CvGxSsCzBN_w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import gzip\n",
        "import shutil\n",
        "\n",
        "# Filter for files with .gz extension\n",
        "gz_files = [file for file in dir_files if file.endswith('.gz')]\n",
        "\n",
        "for gzfile in gz_files:\n",
        "  print(gzfile)\n",
        "  #!tar -xzvf {gzfile}\n",
        "\n",
        "# Path to the input .gz file\n",
        "input_gz_file = os.path.join(dataset_folder,gz_files[0])\n",
        "print(type(input_gz_file))\n",
        "\n",
        "# Path to the output uncompressed file (without .gz extension)\n",
        "output_file = 'image'\n",
        "output_path = os.path.join(dataset_folder,output_file)\n",
        "\n",
        "# Open the .gz file and the output file, then decompress and write the data\n",
        "with gzip.open(input_gz_file, 'rb') as f_in, open(output_path, 'wb') as f_out:\n",
        "    shutil.copyfileobj(f_in, f_out)\n",
        "\n",
        "print(f'File {input_gz_file} has been successfully decompressed to {output_path}.')\n",
        "print(os.listdir())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9vTUMdVfUhy",
        "outputId": "2de46e9a-23f1-42b6-a7ec-ad6d0b67285e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t10k-images-idx3-ubyte.gz\n",
            "t10k-labels-idx1-ubyte.gz\n",
            "<class 'str'>\n",
            "File /content/mnist_dataset/t10k-images-idx3-ubyte.gz has been successfully decompressed to /content/mnist_dataset/image.\n",
            "['t10k-images-idx3-ubyte.gz', 't10k-labels-idx1-ubyte.gz', 'image']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Another dataset - Skip"
      ],
      "metadata": {
        "id": "ngG7vpOqsJeN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "(train_X, train_y), (test_X, test_y) = mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZIhuccyi8O5",
        "outputId": "606f462a-ed8d-48d2-e744-7820d92e4cb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dataset from TorchVision - Skip\n",
        "\n",
        "Try putting this into deeplake -> but I didn't find any way to import PIL images into deeplake\n",
        "\n",
        "Can refer to this [website](https://docs.deeplake.ai/en/latest/Compressions.html) about the compression and data types that can be stored in the deeplake dataset\n",
        "\n",
        "However,\n",
        "Deeplake already has the mnist data set which can be seen [here](https://app.activeloop.ai/activeloop/mnist-test/)"
      ],
      "metadata": {
        "id": "k3KKKsMsikJ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "print(torch.__version__)\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=None)\n",
        "mnist_testset = datasets.MNIST(root='./data', train=False, download=True, transform=None)\n",
        "print(\"Length of trainset : \",len(mnist_trainset))\n",
        "print(\"Length of test set : \",len(mnist_testset))\n",
        "front_data, back_data = mnist_trainset[6]\n",
        "print(\"Type of data in train dataset : \", type(mnist_trainset[0]), type(front_data), type(back_data))\n",
        "display(front_data)\n",
        "print(back_data)\n",
        "\n",
        "os.chdir('data')\n",
        "print(os.listdir())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        },
        "id": "2UYX1rJSicSz",
        "outputId": "d97a5a5a-9d40-45d9-91f1-b304e530dc4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0.1+cu118\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 74711288.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 33361524.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|██████████| 1648877/1648877 [00:00<00:00, 19596978.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 14586928.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Length of trainset :  60000\n",
            "Length of test set :  10000\n",
            "Type of data in train dataset :  <class 'tuple'> <class 'PIL.Image.Image'> <class 'int'>\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAh0lEQVR4nGNgGGAw8f9leVxyCm///nFHFmBCYr8+hKYaWfLrQzySAvp4JLnkGBhMcbqo9u+fPzm4JBnQJJlQJJkYGZG5LCiS//7jdBAGIEGSiZHRDqfSv3/+/NHCpXMGAwNDGi7JG/hcwHDr79//yjh0Mlz9//8fLmMZZqHw0CSvXcdrKx0AAOciI63Ko1kqAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "['MNIST', 'data']\n",
            "['MNIST']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WEjpHICQJAbw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Start Here"
      ],
      "metadata": {
        "id": "iMSH4FYXJDGK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load data\n",
        "1. Download the mnist jpg dataset from kaggle\n",
        "2. Extract the files\n",
        "3. Upload the jpgs to deeplake dataset\n"
      ],
      "metadata": {
        "id": "i1KxEM2z9Unw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opendatasets\n",
        "import opendatasets as od\n",
        "od.download(\"https://www.kaggle.com/datasets/scolianni/mnistasjpg/data\")\n",
        "clear_output()\n",
        "print(os.listdir())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuITL_AVwhJv",
        "outputId": "6408d6ad-4c2f-4575-e568-08ac00568c56"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['.config', 'mnistasjpg', 'animals_deeplake', 'mnist_jpg', 'animals']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dataset in deeplake format\n",
        "deep_lake_path = \"hub://organization_name/dataset_name\"\n",
        "\n",
        "ds = deeplake.empty('./mnist_jpg', overwrite=True) # Create the dataset locally\n",
        "\n",
        "# Find the class_names and list of files that need to be uploaded\n",
        "dataset_folder = './mnistasjpg'\n",
        "cwd = os.getcwd()\n",
        "print(\"Current working directory:\", cwd)\n",
        "\n",
        "# Find the subfolders, but filter additional files like DS_Store that are added on Mac machines.\n",
        "set_names = [item for item in os.listdir(dataset_folder) if os.path.isdir(os.path.join(dataset_folder, item))]\n",
        "print(set_names)\n",
        "\n",
        "# gets the label list from the training sett filders\n",
        "#\n",
        "# !!!!! because the order of the trainingSet list is different from Training Sample so be careful\n",
        "#\n",
        "\n",
        "trainset_folder = os.path.join(dataset_folder,'trainingSet/trainingSet')\n",
        "class_names = [item for item in os.listdir(trainset_folder) if os.path.isdir(os.path.join(trainset_folder, item))]\n",
        "print(class_names)\n",
        "\n",
        "files_list = []\n",
        "\n",
        "# Get only files in trainingSet\n",
        "\n",
        "for dirpath, dirnames, filenames in os.walk(dataset_folder):\n",
        "  print(\"Dirpath : \", dirpath)\n",
        "  #print(\"Dirname : \", dirnames)\n",
        "  if dirpath.startswith(os.path.join(dataset_folder, 'trainingSet')) and os.path.basename(dirpath) in ['3','1','2','4','5','6','7','8','9']: #,'testSet', 'testSample']:\n",
        "    for filename in filenames:\n",
        "      #print(\"filename : \", filename)\n",
        "      files_list.append(os.path.join(dirpath, filename))\n",
        "#print(files_list)\n",
        "print(len(files_list))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICHF6S1-9Kod",
        "outputId": "b0687df5-d161-44f5-d9c8-4e12972eb1cd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./mnist_jpg loaded successfully.\n",
            "Current working directory: /content\n",
            "['testSet', 'testSample', 'trainingSample', 'trainingSet']\n",
            "['3', '0', '5', '4', '7', '8', '1', '6', '2', '9']\n",
            "Dirpath :  ./mnistasjpg\n",
            "Dirpath :  ./mnistasjpg/testSet\n",
            "Dirpath :  ./mnistasjpg/testSet/testSet\n",
            "Dirpath :  ./mnistasjpg/testSample\n",
            "Dirpath :  ./mnistasjpg/testSample/testSample\n",
            "Dirpath :  ./mnistasjpg/trainingSample\n",
            "Dirpath :  ./mnistasjpg/trainingSample/trainingSample\n",
            "Dirpath :  ./mnistasjpg/trainingSample/trainingSample/3\n",
            "Dirpath :  ./mnistasjpg/trainingSample/trainingSample/0\n",
            "Dirpath :  ./mnistasjpg/trainingSample/trainingSample/5\n",
            "Dirpath :  ./mnistasjpg/trainingSample/trainingSample/4\n",
            "Dirpath :  ./mnistasjpg/trainingSample/trainingSample/7\n",
            "Dirpath :  ./mnistasjpg/trainingSample/trainingSample/8\n",
            "Dirpath :  ./mnistasjpg/trainingSample/trainingSample/1\n",
            "Dirpath :  ./mnistasjpg/trainingSample/trainingSample/6\n",
            "Dirpath :  ./mnistasjpg/trainingSample/trainingSample/2\n",
            "Dirpath :  ./mnistasjpg/trainingSample/trainingSample/9\n",
            "Dirpath :  ./mnistasjpg/trainingSet\n",
            "Dirpath :  ./mnistasjpg/trainingSet/trainingSet\n",
            "Dirpath :  ./mnistasjpg/trainingSet/trainingSet/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dirpath :  ./mnistasjpg/trainingSet/trainingSet/0\n",
            "Dirpath :  ./mnistasjpg/trainingSet/trainingSet/5\n",
            "Dirpath :  ./mnistasjpg/trainingSet/trainingSet/4\n",
            "Dirpath :  ./mnistasjpg/trainingSet/trainingSet/7\n",
            "Dirpath :  ./mnistasjpg/trainingSet/trainingSet/8\n",
            "Dirpath :  ./mnistasjpg/trainingSet/trainingSet/1\n",
            "Dirpath :  ./mnistasjpg/trainingSet/trainingSet/6\n",
            "Dirpath :  ./mnistasjpg/trainingSet/trainingSet/2\n",
            "Dirpath :  ./mnistasjpg/trainingSet/trainingSet/9\n",
            "37868\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the dataset tensors and Upload metadata"
      ],
      "metadata": {
        "id": "Xzg1mn3DSx19"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "with ds:\n",
        "    # Create the tensors with names of your choice.\n",
        "    ds.create_tensor('images', htype = 'image', sample_compression = 'jpeg', exist_ok=True)\n",
        "    ds.create_tensor('labels', htype = 'class_label', class_names = class_names, exist_ok=True)\n",
        "\n",
        "    # Add arbitrary metadata - Optional\n",
        "    #ds.info.update(description = 'My first Deep Lake dataset')\n",
        "    #ds.images.info.update(camera_type = 'SLR')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvuLkvmQShfF",
        "outputId": "5d96361b-ae39-4b28-d7b9-a0f26aa25c64"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r\r"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "populate the data in the tensors"
      ],
      "metadata": {
        "id": "2i6F1bwpS2qP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "load_data2_start = time.time()\n",
        "with ds:\n",
        "    # Iterate through the files and append to Deep Lake dataset\n",
        "    for file in files_list:\n",
        "        label_text = os.path.basename(os.path.dirname(file))\n",
        "        #print(label_text)\n",
        "        label_num = class_names.index(label_text)\n",
        "\n",
        "        #Append data to the tensors\n",
        "        ds.append({'images': deeplake.read(file), 'labels': np.uint32(label_num)})\n",
        "\n",
        "  # Warning !!! :  Grayscale images will be reshaped from (H, W) to (H, W, 1) to match tensor dimensions.\n",
        "load_data2_end = time.time()\n",
        "\n",
        "data_load_time = load_data2_end - load_data2_start\n",
        "print(data_load_time)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocOCLOx6S2Tr",
        "outputId": "14879906-0aaa-4483-e7b6-d9b6eb8286c6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/deeplake/core/chunk/base_chunk.py:421: UserWarning: Grayscale images will be reshaped from (H, W) to (H, W, 1) to match tensor dimensions. This warning will be shown only once.\n",
            "  warnings.warn(message)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "83.73714447021484\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r\r"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem : the image that is stored into the deeplake dataset cannot be recognized after transforming into a PIL image\n",
        "\n",
        "The reason is the shape is (28,28,1) I think because there is only 1 dimension on the 0 axis because it is a gray scale image\n",
        "\n",
        "So we have to squeeze it to a (28,28) so that it can recognize"
      ],
      "metadata": {
        "id": "BlHPGMRvcr3S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#print(type(ds.images[0].numpy()))\n",
        "#print(ds.images[0].numpy())\n",
        "im0 = ds.images[0].numpy()\n",
        "### !!!!!!!!!!!!!!!!!!!!!!!!!\n",
        "\n",
        "im0 = np.squeeze(im0, axis=2)\n",
        "\n",
        "### !!!!!!!!!!!!!!!!!!!!!!!!!\n",
        "pil0 = Image.fromarray(im0)\n",
        "display(pil0)\n",
        "\n",
        "label0 = ds.labels[0].numpy()\n",
        "print(label0)\n",
        "#Image.fromarray(ds.images[0].numpy())\n",
        "ds.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "lw8esCMjVCL1",
        "outputId": "f70d53e5-dc5a-430d-91a6-979e5db5dff8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAB9ElEQVR4nMWQvWtTYRjFf+/nfXOTm6YJbSqilIgFobp0FVcnRTdFUAdBQRB0EwQRp5aCLo6CCJ2c3BTBzuJUER2KFepQC6a2TdJ83Nv7OCT5Gzzr4fye8xxitIMIC6WAJYZgDJqhlAkhJoB3+ElcBUJ1ZHkH2hjKAVSEx5oi2gxdY8BhbIQJWIcCi2OsQgTUH79ba8vXp9MzruwZucai4e6SSKcnIiJLU6gCU6Ochslfsivbm3+3mlmarZ8cIxUuJfTeb/z89qEf9eev3bf6+J+eVocAeOcVGkigRuVL3n1JNHozREAl0rHBWY6tSCqPKFIFsD10XtrP0Q0TNy5cSuT3x9ek8Q4AERGW4vLbQ2mK7Ha2boJjuIG25GTU5y7uU20NQpw1Z+tpOHTDthS6PssbLya6bzZ9/eHRwfbK4oHrDxt5hYkhBgN2YVXk4BmEUV0FOEcFPKjy7S2Rq/hREspgCxShiEVf+SQyP94owAwxCTVNDCUe7PeWHYBV0o/VXtKyLXZzm5akXZgtqdN6TMXfWvuu0JFFo6HZloloxK2hRPJXN+5N+hKW4sKPbvvy8GLSslltozxo1bJ29vnEaj59NonX55QMR9C5PnLHnz/l2ZuglXSC2W4UdgRQLiX0KHTL585UO9drSS/w/Ena8QP+j/4BnhuheTh890YAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\n",
            "Dataset(path='./mnist_jpg', tensors=['images', 'labels'])\n",
            "\n",
            " tensor      htype           shape          dtype  compression\n",
            " -------    -------         -------        -------  ------- \n",
            " images      image     (37868, 28, 28, 1)   uint8    jpeg   \n",
            " labels   class_label      (37868, 1)      uint32    None   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Test loading - Skip (just for verification)\n",
        "I manually uploaded a few jpg files to test its functionality\n",
        "\n",
        "It is normal if it doesn't work"
      ],
      "metadata": {
        "id": "k-iYGueNWgPs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "# Find the class_names and list of files that need to be uploaded\n",
        "dataset_folder = './animals'\n",
        "\n",
        "ds_animal = deeplake.empty('./animals_deeplake', overwrite=True)\n",
        "\n",
        "# Find the subfolders, but filter additional files like DS_Store that are added on Mac machines.\n",
        "class_names = [item for item in os.listdir(dataset_folder) if os.path.isdir(os.path.join(dataset_folder, item))]\n",
        "\n",
        "files_list = []\n",
        "for dirpath, dirnames, filenames in os.walk(dataset_folder):\n",
        "    for filename in filenames:\n",
        "        files_list.append(os.path.join(dirpath, filename))\n",
        "\n",
        "with ds_animal:\n",
        "    # Create the tensors with names of your choice.\n",
        "    ds_animal.create_tensor('images', htype = 'image', sample_compression = 'jpeg', exist_ok=True)\n",
        "    ds_animal.create_tensor('labels', htype = 'class_label', class_names = class_names , exist_ok=True)\n",
        "\n",
        "    # Add arbitrary metadata - Optional\n",
        "    ds_animal.info.update(description = 'My first Deep Lake dataset')\n",
        "    ds_animal.images.info.update(camera_type = 'SLR')\n",
        "\n",
        "with ds_animal:\n",
        "    # Iterate through the files and append to Deep Lake dataset\n",
        "    for file in files_list:\n",
        "        label_text = os.path.basename(os.path.dirname(file))\n",
        "        label_num = class_names.index(label_text)\n",
        "\n",
        "        #Append data to the tensors\n",
        "        ds_animal.append({'images': deeplake.read(file), 'labels': np.uint32(label_num)})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhDfF2HIWL1E",
        "outputId": "95c5b1e5-3ba3-4044-c54c-2e25439732e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "./animals_deeplake loaded successfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r\r\r\r\r\r"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print(type(ds_animal.images[0]))\n",
        "print(ds_animal.images[0].numpy().shape)\n",
        "print(ds_animal.labels[0].numpy())\n",
        "#print(ds_animal.images[0].numpy())\n",
        "\n",
        "im = Image.fromarray(ds_animal.images[0].numpy())\n",
        "print(type(im))\n",
        "ds_animal.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWQfMwuGYDfj",
        "outputId": "7bec807d-b4fa-4f39-a609-bcf9dd77fd2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(960, 640, 3)\n",
            "[0]\n",
            "<class 'PIL.Image.Image'>\n",
            "Dataset(path='./animals_deeplake', tensors=['images', 'labels'])\n",
            "\n",
            " tensor      htype             shape           dtype  compression\n",
            " -------    -------           -------         -------  ------- \n",
            " images      image     (4, 427:1026, 640, 3)   uint8    jpeg   \n",
            " labels   class_label         (4, 1)          uint32    None   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Deeplake builtin Mnist dataset\n",
        "1. Use builtin dataloader to load the data\n",
        "2. To make the comparison accurate, use the model specified in EvaDB\n",
        "3. Perform model testing using the test data set"
      ],
      "metadata": {
        "id": "yR-Jc0P3BzCY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load Data"
      ],
      "metadata": {
        "id": "gPz5fEY2CyUf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect to the training and testing datasets\n",
        "ds_train = deeplake.load('hub://activeloop/mnist-train')\n",
        "ds_test = deeplake.load('hub://activeloop/mnist-test')"
      ],
      "metadata": {
        "id": "I3LT-x4O9IVN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a12d1028-2504-4033-94b4-890305d45886"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Opening dataset in read-only mode as you don't have write permissions.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\\"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/activeloop/mnist-train\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\\"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hub://activeloop/mnist-train loaded successfully.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Opening dataset in read-only mode as you don't have write permissions.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "|"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/activeloop/mnist-test\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "|"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hub://activeloop/mnist-test loaded successfully.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r \r\r\r"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print data type and data stored using the dataloader\n",
        "\n",
        "We can see the image is still in PIL but the dataloader is different from on in pytorch"
      ],
      "metadata": {
        "id": "nN9PLmu5C3zn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display(ds_train)\n",
        "print(\"Type of data in deeplake dataset : \", type(ds_train[0]))\n",
        "\n",
        "print(ds_train.images[0].numpy().shape)\n",
        "print(ds_train.labels[0].numpy().shape)\n",
        "\n",
        "img = ds_train.images[0].numpy()\n",
        "print(\"Type of image in deeplake dataset : \", type(img))\n",
        "img.shape\n",
        "label = ds_train.labels[0].numpy()\n",
        "print(\"Type of label in deeplake dataset : \", type(label))\n",
        "label.shape\n",
        "display(Image.fromarray(ds_train.images[0].numpy(), \"L\"))\n",
        "print(label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "aNT2FxaCjaIm",
        "outputId": "f7c659a6-1af4-45b5-f82b-fdb4a3c0e626"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dataset(path='hub://activeloop/mnist-train', read_only=True, tensors=['images', 'labels'])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type of data in deeplake dataset :  <class 'deeplake.core.dataset.deeplake_cloud_dataset.DeepLakeCloudDataset'>\n",
            "(28, 28)\n",
            "(1,)\n",
            "Type of image in deeplake dataset :  <class 'numpy.ndarray'>\n",
            "Type of label in deeplake dataset :  <class 'numpy.ndarray'>\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABAElEQVR4nGNgGMyAWUhIqK5jvdSy/9/rGRgYGFhgEnJsVjYCwQwMDAxPJgV+vniQgYGBgREqZ7iXH8r6l/SV4dn7m8gmCt3++/fv37/Htn3/iMW+gDnZf/+e5WbQnoXNNXyMs/5GoQoxwVmf/n9kSGFiwAW49/11wynJoPzx4YIcRlyygR/+/i2XxCWru+vv32nSuGQFYv/83Y3b4p9/fzpAmSyoMnohpiwM1w5h06Q+5enfv39/bcMiJVF09+/fv39P+mFKiTtd/fv3799jgZiBJLT69t+/f/8eDuDEkDJf8+jv379/v7Ryo4qzMDAwMAQGMjBc3/y35wM2V1IfAABFF16Aa0wAOwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Mnist Model"
      ],
      "metadata": {
        "id": "LMUifMY_Dt-z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notes :  \n",
        "\n",
        "Try to use the model that was provided in evadb [github](https://github.com/aaron-xichen/pytorch-playground/blob/master/utee/selector.py).\n",
        "\n",
        "The problem was that it used the selector to activate the mnist.py but because the hardware he was using had GPUs or CUDAs ? so there will be errors for me.\n",
        "\n",
        "But it occurred to me that I could run the mnist in Eva DB so I think using the one in Evadb will work."
      ],
      "metadata": {
        "id": "jMURJUM-m6b1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Specify Device"
      ],
      "metadata": {
        "id": "g-Fyiq18EEJR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# this was from the deeplake code example\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-O85C5van0wG",
        "outputId": "b7c420b2-642a-449a-a5f0-476bbb1d6e66"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from collections import OrderedDict\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "\n",
        "model_urls = {\n",
        "    'mnist': 'http://ml.cs.tsinghua.edu.cn/~chenxi/pytorch-models/mnist-b07bb66b.pth'\n",
        "}"
      ],
      "metadata": {
        "id": "V7vL9FzQpaoX"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# here EvaDB used a class name called MnistImageClassifier - I think I will have to know how they call this function or\n",
        "# how they run the model on there data using sql\n",
        "class MLP(nn.Module):\n",
        "  def __init__(self, input_dims, n_hiddens, n_class):\n",
        "    super(MLP, self).__init__()\n",
        "    assert isinstance(input_dims, int), 'Please provide int for input_dims'\n",
        "    self.input_dims = input_dims\n",
        "    current_dims = input_dims\n",
        "    layers = OrderedDict()\n",
        "\n",
        "    if isinstance(n_hiddens, int):\n",
        "        n_hiddens = [n_hiddens]\n",
        "    else:\n",
        "        n_hiddens = list(n_hiddens)\n",
        "    for i, n_hidden in enumerate(n_hiddens):\n",
        "        layers['fc{}'.format(i+1)] = nn.Linear(current_dims, n_hidden)\n",
        "        layers['relu{}'.format(i+1)] = nn.ReLU()\n",
        "        layers['drop{}'.format(i+1)] = nn.Dropout(0.2)\n",
        "        current_dims = n_hidden\n",
        "    layers['out'] = nn.Linear(current_dims, n_class)\n",
        "\n",
        "    self.model= nn.Sequential(layers)\n",
        "    print(self.model)\n",
        "\n",
        "  def forward(self, input):\n",
        "    input = input.view(input.size(0), -1)\n",
        "    assert input.size(1) == self.input_dims\n",
        "    return self.model.forward(input)\n",
        "\n",
        "def mnist(input_dims=784, n_hiddens=[256, 256], n_class=10, pretrained=None):\n",
        "  model = MLP(input_dims, n_hiddens, n_class)\n",
        "  if pretrained is not None:\n",
        "      m = model_zoo.load_url(model_urls['mnist'],\n",
        "                             map_location=torch.device(device)) # this is the line where EvaDB was different from the github code\n",
        "      state_dict = m.state_dict() if isinstance(m, nn.Module) else m\n",
        "      assert isinstance(state_dict, (dict, OrderedDict)), type(state_dict)\n",
        "      model.load_state_dict(state_dict)\n",
        "  return model\n",
        "\n",
        "# EvaDB uses other functions in their self-defined Class to do transform and turning data to panda\n",
        "\n"
      ],
      "metadata": {
        "id": "Z2pzamDIpoFQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test function"
      ],
      "metadata": {
        "id": "DGOd-NLDENeI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def test_model(model, data_loader, device):\n",
        "  model.eval()\n",
        "\n",
        "  start_time = time.time()\n",
        "  total = 0;\n",
        "  correct = 0\n",
        "  with torch.no_grad(): # this deactivates the gradient computation which is not needed for model evaluation and inference, turning this off can make things run faster , this is mostky for backpropagation while training\n",
        "    for i, data in enumerate(data_loader): # here we use the data in the data_loader , but because it is not transformed so I don;t know if it will work\n",
        "      inputs = data['images']\n",
        "      labels = torch.squeeze(data['labels'])\n",
        "\n",
        "      #print(inputs)\n",
        "\n",
        "      inputs = inputs.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      # chatgpt said that this line is not needed and should be removed\n",
        "      #optimizer.zero_grad()\n",
        "\n",
        "      # chatgpt says that this only does forward pass\n",
        "      outputs = model(inputs.float())\n",
        "\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      total += labels.size(0)\n",
        "      #print(\"Predicted : \", predicted)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "      accuracy = 100 * correct / total\n",
        "\n",
        "      #outcome = []\n",
        "      #predictions = model(inputs)\n",
        "      #for prediction in predictions:\n",
        "      #  label = model.as_numpy(prediction.data.argmax())\n",
        "      #  outcome.append({\"label\": str(label)})\n",
        "\n",
        "      # Print predictions, actual labels, and images\n",
        "      # for j in range(inputs.size(0)):\n",
        "      #     print('Prediction: {}, Actual Label: {}'.format(predicted[j].item(), labels[j].item()))\n",
        "      #     #Assuming inputs are PIL images, you can use matplotlib to display the images\n",
        "      #     plt.imshow(inputs[j].permute(1, 2, 0).cpu().numpy())  # Assuming channels-last format\n",
        "      #     plt.show()\n",
        "\n",
        "      #     image_np = inputs[j].permute(1, 2, 0).cpu().numpy()\n",
        "      #     image_2d = image_np[:, :, 0]\n",
        "      #     display(Image.fromarray(image_2d, \"L\"))\n",
        "      #print(i)\n",
        "      # if i%15 == 0:\n",
        "      #   print('Prediction: {}, Actual Label: {}'.format(predicted[0].item(), labels[0].item()))\n",
        "      #   #Assuming inputs are PIL images, you can use matplotlib to display the images\n",
        "      #   plt.imshow(inputs[0].permute(1, 2, 0).cpu().numpy())  # Assuming channels-last format\n",
        "      #   plt.show()\n",
        "      #   # this printing doesn't work I guess\n",
        "      #   image_np = inputs[0].permute(1, 2, 0).cpu().numpy()\n",
        "      #   image_2d = image_np[:, :, 0]\n",
        "      #   display(Image.fromarray(image_2d, \"L\"))\n",
        "\n",
        "      print('Finished Testing')\n",
        "      #print('Total images: {}, Correct: {}'.format(total, correct))\n",
        "      print('Testing accuracy: %.1f %%' %(accuracy))\n"
      ],
      "metadata": {
        "id": "4WF_DtjUSsFL"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_pred_model(model, data_loader, device, pred_num):\n",
        "  model.eval()\n",
        "\n",
        "  result = []\n",
        "  with torch.no_grad(): # this deactivates the gradient computation which is not needed for model evaluation and inference, turning this off can make things run faster , this is mostky for backpropagation while training\n",
        "    for i, data in enumerate(data_loader): # here we use the data in the data_loader , but because it is not transformed so I don;t know if it will work\n",
        "      inputs = data['images']\n",
        "      labels = torch.squeeze(data['labels'])\n",
        "\n",
        "      inputs = inputs.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      # chatgpt says that this only does forward pass\n",
        "      outputs = model(inputs.float())\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      for j in range(inputs.size(0)):\n",
        "        if predicted[j].item()==pred_num:\n",
        "          result.append(inputs[j])\n",
        "\n",
        "  return result"
      ],
      "metadata": {
        "id": "beXWVnikEOgU"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# why do we need a transform here?\n",
        "# This was the transform function for pretrained ResNet18 neural network from torchvision.models\n",
        "'''\n",
        "tform = transforms.Compose([\n",
        "   transforms.RandomRotation(20), # Image augmentation\n",
        "   transforms.ToTensor(), # Must convert to pytorch tensor for subsequent operations to run\n",
        "   transforms.Normalize([0.5], [0.5]),\n",
        "])\n",
        "'''\n",
        "\n",
        "tform = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])"
      ],
      "metadata": {
        "id": "ITxmRW2ziHP4"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Test model\n",
        "Currently there are bugs when doing the test because the labels are incorrectly stored into the dataset, but the predictions are right"
      ],
      "metadata": {
        "id": "Y66si0L8FCnh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 100\n",
        "\n",
        "# Since torchvision transforms expect PIL images, we use the 'pil' decode_method for the 'images' tensor. This is much faster than running ToPILImage inside the transform\n",
        "\n",
        "#train_loader = ds_train.pytorch(num_workers = 0, shuffle = True, transform = {'images': tform, 'labels': None}, batch_size = batch_size, decode_method = {'images': 'pil'})\n",
        "#test_loader = ds_test.pytorch(num_workers = 0, transform = {'images': tform, 'labels': None}, batch_size = batch_size, decode_method = {'images': 'pil'})\n",
        "\n",
        "#hope this works\n",
        "mnist_loader = ds.pytorch(num_workers = 0, transform = {'images': tform, 'labels': None}, batch_size = batch_size, decode_method = {'images': 'pil'})\n"
      ],
      "metadata": {
        "id": "9_36uFr3mwtU"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = mnist(pretrained=True)\n",
        "#test_model(model, test_loader, device)\n",
        "\n",
        "#print(\"Type of model is : \", type(model))\n",
        "runall_start = time.time()\n",
        "test_model(model, mnist_loader, device)\n",
        "runall_end = time.time()\n",
        "\n",
        "runall_time = runall_end - runall_start\n",
        "print(f\"Run all data time : {runall_time} seconds\")\n",
        "\n",
        "pred_num = 6\n",
        "query_start = time.time()\n",
        "\n",
        "get_label6 = get_pred_model(model, mnist_loader, device, pred_num)\n",
        "# print(type(get_label6[0]))\n",
        "# for i in range(0,len(get_label6)-1) :\n",
        "#   plt.imshow(get_label6[i].permute(1, 2, 0).cpu().numpy())  # Assuming channels-last format\n",
        "#   plt.show()\n",
        "\n",
        "query_end = time.time()\n",
        "query_time = query_end - query_start\n",
        "print(f\"Query data time : {query_time} seconds\")\n",
        "\n",
        "#this can print out the plots of results\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dNkHRYjtXfY",
        "outputId": "29d44a6b-4208-4801-b418-67c8546effb6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (fc1): Linear(in_features=784, out_features=256, bias=True)\n",
            "  (relu1): ReLU()\n",
            "  (drop1): Dropout(p=0.2, inplace=False)\n",
            "  (fc2): Linear(in_features=256, out_features=256, bias=True)\n",
            "  (relu2): ReLU()\n",
            "  (drop2): Dropout(p=0.2, inplace=False)\n",
            "  (out): Linear(in_features=256, out_features=10, bias=True)\n",
            ")\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.1 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.4 %\n",
            "Finished Testing\n",
            "Testing accuracy: 0.7 %\n",
            "Finished Testing\n",
            "Testing accuracy: 1.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 1.3 %\n",
            "Finished Testing\n",
            "Testing accuracy: 1.5 %\n",
            "Finished Testing\n",
            "Testing accuracy: 1.8 %\n",
            "Finished Testing\n",
            "Testing accuracy: 2.1 %\n",
            "Finished Testing\n",
            "Testing accuracy: 2.4 %\n",
            "Finished Testing\n",
            "Testing accuracy: 2.7 %\n",
            "Finished Testing\n",
            "Testing accuracy: 3.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 3.2 %\n",
            "Finished Testing\n",
            "Testing accuracy: 3.5 %\n",
            "Finished Testing\n",
            "Testing accuracy: 3.8 %\n",
            "Finished Testing\n",
            "Testing accuracy: 4.1 %\n",
            "Finished Testing\n",
            "Testing accuracy: 4.3 %\n",
            "Finished Testing\n",
            "Testing accuracy: 4.6 %\n",
            "Finished Testing\n",
            "Testing accuracy: 4.9 %\n",
            "Finished Testing\n",
            "Testing accuracy: 5.1 %\n",
            "Finished Testing\n",
            "Testing accuracy: 5.4 %\n",
            "Finished Testing\n",
            "Testing accuracy: 5.7 %\n",
            "Finished Testing\n",
            "Testing accuracy: 5.9 %\n",
            "Finished Testing\n",
            "Testing accuracy: 6.2 %\n",
            "Finished Testing\n",
            "Testing accuracy: 6.4 %\n",
            "Finished Testing\n",
            "Testing accuracy: 6.7 %\n",
            "Finished Testing\n",
            "Testing accuracy: 7.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 7.2 %\n",
            "Finished Testing\n",
            "Testing accuracy: 7.5 %\n",
            "Finished Testing\n",
            "Testing accuracy: 7.7 %\n",
            "Finished Testing\n",
            "Testing accuracy: 8.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 8.2 %\n",
            "Finished Testing\n",
            "Testing accuracy: 8.5 %\n",
            "Finished Testing\n",
            "Testing accuracy: 8.7 %\n",
            "Finished Testing\n",
            "Testing accuracy: 9.0 %\n",
            "Finished Testing\n",
            "Testing accuracy: 9.2 %\n",
            "Finished Testing\n",
            "Testing accuracy: 9.5 %\n",
            "Finished Testing\n",
            "Testing accuracy: 9.7 %\n",
            "Finished Testing\n",
            "Testing accuracy: 9.9 %\n",
            "Finished Testing\n",
            "Testing accuracy: 10.2 %\n",
            "Finished Testing\n",
            "Testing accuracy: 10.4 %\n",
            "Finished Testing\n",
            "Testing accuracy: 10.7 %\n",
            "Finished Testing\n",
            "Testing accuracy: 10.9 %\n",
            "Finished Testing\n",
            "Testing accuracy: 11.0 %\n",
            "Run all data time : 33.17898464202881 seconds\n",
            "Query data time : 29.44153928756714 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Run Query - Still working\n",
        "In deeplake they call it Tensor query maybe because the data stored in the database are Tensors"
      ],
      "metadata": {
        "id": "Db0G3GbT0tg0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = f\"select images where labels==6\"\n",
        "result = ds.query(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "hcDsXbUV0wTl",
        "outputId": "4bb71de6-527c-4ddb-932d-166e1714afc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "EmptyTokenException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mEmptyTokenException\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-164-e6d0b086987e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"select images where labels==6\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/deeplake/core/dataset/dataset.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, query_string, runtime, return_data)\u001b[0m\n\u001b[1;32m   2329\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mdeeplake\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menterprise\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2331\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2333\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_string\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mQUERY_MESSAGE_MAX_SIZE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/deeplake/enterprise/libdeeplake_query.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(dataset, query_string)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mslice_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_to_libdeeplake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0mdsv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mdeeplake\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menterprise\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_libdeeplake\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mINDRA_API\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/deeplake/enterprise/convert_to_libdeeplake.py\u001b[0m in \u001b[0;36mdataset_to_libdeeplake\u001b[0;34m(hub2_dataset)\u001b[0m\n\u001b[1;32m    160\u001b[0m     )\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mEmptyTokenException\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhub2_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlibdeeplake_dataset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0mlibdeeplake_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mEmptyTokenException\u001b[0m: The authentication token is empty."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#End"
      ],
      "metadata": {
        "id": "cHFj6nnW5UXJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we want to use the pytorch function of the dataset of the function deeplake.load then we have to store the data into deeplake\n",
        "Deeplake provides a pytorch dataloader that connects the Deep Lake dataset to the PyTorch model using the provided method ds.pytorch().\n",
        "\n",
        "This method automatically applies the transformation function and takes care of random shuffling (if desired). The num_workers parameter can be used to parallelize data preprocessing, which is critical for ensuring that preprocessing does not bottleneck the overall training workflow.\n",
        "The transform input is a dictionary where the key is the tensor name and the value is the transformation function that should be applied to that tensor. If a specific tensor's data does not need to be returned, it should be omitted from the keys. If a tensor's data does not need to be modified during preprocessing, the transformation function is set as None, which will convert the input data to a torch tensor."
      ],
      "metadata": {
        "id": "zqr0sDLtiJf4"
      }
    }
  ]
}